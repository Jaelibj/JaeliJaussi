[
  {
    "objectID": "Full_Stack/project5.html",
    "href": "Full_Stack/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 5"
    ]
  },
  {
    "objectID": "Full_Stack/project4.html",
    "href": "Full_Stack/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 4"
    ]
  },
  {
    "objectID": "Full_Stack/project3.html",
    "href": "Full_Stack/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 3"
    ]
  },
  {
    "objectID": "notebooks/Exploration_02.html#part-1-import-pandas-and-load-the-data",
    "href": "notebooks/Exploration_02.html#part-1-import-pandas-and-load-the-data",
    "title": "Data Exploration 02",
    "section": "Part 1: Import Pandas and load the data",
    "text": "Part 1: Import Pandas and load the data\nRemember to import Pandas the conventional way. If you‚Äôve forgotten how, you may want to review Data Exploration 01.\nThe dataset for this exploration is stored at the following url:\nhttps://raw.githubusercontent.com/byui-cse/cse450-course/master/data/cereal.csv\nThere are lots of ways to load data into your workspace. The easiest way in this case is to ask Pandas to do it for you.\n\nInitial Data Analysis\nOnce you‚Äôve loaded the data, it‚Äôs a good idea to poke around a little bit to find out what you‚Äôre dealing with.\nSome questions you might ask include:\n\nWhat does the data look like?\nWhat kind of data is in each column?\nDo any of the columns have missing values?\n\n\n# Part 1: Enter your code below to import Pandas according to the\n# conventional method. Then load the dataset into a Pandas dataframe.\nimport pandas as pd\n\ncereal = pd.read_csv(\"https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/cereal.csv\")\n\n# Write any code needed to explore the data by seeing what the first few\n# rows look like. Then display a technical summary of the data to determine\n# the data types of each column, and which columns have missing data.\ncereal.head()\n\n\n    \n\n\n\n\n\n\nname\nmfr\ntype\ncalories\nprotein\nfat\nsodium\nfiber\ncarbo\nsugars\npotass\nvitamins\nshelf\nweight\ncups\nrating\n\n\n\n\n0\n100% Bran\nN\nC\n70\n4\n1\n130\n10.0\n5.0\n6\n280\n25\n3\n1.0\n0.33\n68.402973\n\n\n1\n100% Natural Bran\nQ\nC\n120\n3\n5\n15\n2.0\n8.0\n8\n135\n0\n3\n1.0\n1.00\n33.983679\n\n\n2\nAll-Bran\nK\nC\n70\n4\n1\n260\n9.0\n7.0\n5\n320\n25\n3\n1.0\n0.33\n59.425505\n\n\n3\nAll-Bran with Extra Fiber\nK\nC\n50\n4\n0\n140\n14.0\n8.0\n0\n330\n25\n3\n1.0\n0.50\n93.704912\n\n\n4\nAlmond Delight\nR\nC\n110\n2\n2\n200\n1.0\n14.0\n8\n-1\n25\n3\n1.0\n0.75\n34.384843"
  },
  {
    "objectID": "notebooks/Exploration_02.html#part-2-calculate-summary-statistics",
    "href": "notebooks/Exploration_02.html#part-2-calculate-summary-statistics",
    "title": "Data Exploration 02",
    "section": "Part 2: Calculate Summary Statistics",
    "text": "Part 2: Calculate Summary Statistics\nThe marketing team has determined that when choosing a cereal, consumers are most interested in calories, sugars, fiber, fat, and protein.\nFirst, let‚Äôs calcuate some summary statistics for these categories across the entire dataset. We‚Äôre particularly intrested in the mean, median, standard deviation, min, and max values.\nThere are multiple ways to accomplish this.\n\n# Part 2: Enter your code below to calculate summary statistics for the\n# calories, sugars, fiber, fat, and protein features.\n\ncereal[['calories', 'sugars', 'fiber', 'fat', 'protein']].describe()\n\n\n    \n\n\n\n\n\n\ncalories\nsugars\nfiber\nfat\nprotein\n\n\n\n\ncount\n77.000000\n77.000000\n77.000000\n77.000000\n77.000000\n\n\nmean\n106.883117\n6.922078\n2.151948\n1.012987\n2.545455\n\n\nstd\n19.484119\n4.444885\n2.383364\n1.006473\n1.094790\n\n\nmin\n50.000000\n-1.000000\n0.000000\n0.000000\n1.000000\n\n\n25%\n100.000000\n3.000000\n1.000000\n0.000000\n2.000000\n\n\n50%\n110.000000\n7.000000\n2.000000\n1.000000\n3.000000\n\n\n75%\n110.000000\n11.000000\n3.000000\n2.000000\n3.000000\n\n\nmax\n160.000000\n15.000000\n14.000000\n5.000000\n6.000000"
  },
  {
    "objectID": "notebooks/Exploration_02.html#part-3-transform-data",
    "href": "notebooks/Exploration_02.html#part-3-transform-data",
    "title": "Data Exploration 02",
    "section": "Part 3: Transform Data",
    "text": "Part 3: Transform Data\nTo make analysis easier, you want to convert the manufacturer codes used in the dataset to the manufacturer names.\nFirst, display the count of each manufacturer code value used in the dataset (found in the mfr column).\nThen, create a new column with the appropriate manufacturer name for each entry, using this mapping:\nA = American Home Food Products\nG = General Mills\nK = Kelloggs\nN = Nabisco\nP = Post\nQ = Quaker Oats\nR = Ralston Purina\n\nNote: While the tutorial linked above uses the replace function, using the map function instead can often be much faster and more memory efficient, especially for large datasets.\n\n\n# Display the count of values for the manufacturer code (\"mfr\" column), then\n# create a new column containing the appropriate manufacturer names.\ncereal['mfr_name'] = cereal['mfr'].map({'A': 'American Home Food Products',\n    'G': 'General Mills',\n    'K': 'Kelloggs',\n    'N': 'Nabisco',\n    'P': 'Post',\n    'Q': 'Quaker Oats',\n    'R': 'Ralston Purina'})"
  },
  {
    "objectID": "notebooks/Exploration_02.html#part-4-visualization",
    "href": "notebooks/Exploration_02.html#part-4-visualization",
    "title": "Data Exploration 02",
    "section": "Part 4: Visualization",
    "text": "Part 4: Visualization\nLet‚Äôs do some more data exploration visually.\nImport your visualization library of choice and set any needed configuration options.\n\n# Import your visualization library\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Select Color\nsns.set(style=\"whitegrid\")\n\n\nSugar Distribution\nMarketing tells us that their surveys have revealed that sugar content is the number one concern of consumers when choosing cereal.\nThey would like to see the following visualizations:\n\nA histogram plot of the sugar content in all cereals.\nA scatter plot showing the relationship between sugar and calories.\nA box plot showing the distribution of sugar content by manufacturer.\n\n\n# Create the three visualzations requested by the the marketing team\n# A histogram plot of the sugar content in all cereals.\nplt.figure(figsize=(8, 5))\nsns.histplot(data=cereal, x='sugars', bins=10)\nplt.title(\"Distribution of Sugar Content in Cereals\")\nplt.xlabel(\"Sugar (grams)\")\nplt.ylabel(\"Count\")\nplt.show()\n\n# A scatter plot showing the relationship between sugar and calories.\nplt.figure(figsize=(8, 5))\nsns.scatterplot(data=cereal, x='sugars', y='calories')\nplt.title(\"Sugar vs Calories in Cereals\")\nplt.xlabel(\"Sugar (grams)\")\nplt.ylabel(\"Calories\")\nplt.show()\n\n# A box plot showing the distribution of sugar content by manufacturer.\nplt.figure(figsize=(10, 6))\nsns.boxplot(data=cereal, x='mfr_name', y='sugars')\nplt.title(\"Sugar Content by Manufacturer\")\nplt.xlabel(\"Manufacturer\")\nplt.ylabel(\"Sugar (grams)\")\nplt.xticks(rotation=45)\nplt.show()"
  },
  {
    "objectID": "notebooks/Exploration_02.html#above-and-beyond",
    "href": "notebooks/Exploration_02.html#above-and-beyond",
    "title": "Data Exploration 02",
    "section": "üåü Above and Beyond üåü",
    "text": "üåü Above and Beyond üåü\nThe marketing team is pleased with what you‚Äôve accomplished so far. They have a meeting with top cereal executives in the morning, and they‚Äôd like you to do as many of the following additional tasks as you have time for:\n\nWeight Watchers used to have an older points system that used this formula: (calories / 50) + (fat / 12) - (fiber / 5), but only the first 4 grams of fiber were included in the calculation. For comparison‚Äôs sake, create an additional column with the calculation for the old points system.\nMarketing really likes the boxplot of the sugar content for each cereal, they‚Äôd like similar plots for calories and fat, but using different color schemes for each chart."
  },
  {
    "objectID": "Cleansing_Exploration/project5.html",
    "href": "Cleansing_Exploration/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project4.html",
    "href": "Cleansing_Exploration/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project3.html",
    "href": "Cleansing_Exploration/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project1.html",
    "href": "Cleansing_Projects/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 1"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project2.html",
    "href": "Cleansing_Projects/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 2"
    ]
  },
  {
    "objectID": "Story_Telling/project5.html",
    "href": "Story_Telling/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 5"
    ]
  },
  {
    "objectID": "Story_Telling/project4.html",
    "href": "Story_Telling/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 4"
    ]
  },
  {
    "objectID": "Story_Telling/project3.html",
    "href": "Story_Telling/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 3"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "Machine_Learning/project1.html",
    "href": "Machine_Learning/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 1"
    ]
  },
  {
    "objectID": "Machine_Learning/project2.html",
    "href": "Machine_Learning/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 2"
    ]
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "Competition/project5.html",
    "href": "Competition/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 5"
    ]
  },
  {
    "objectID": "Competition/project4.html",
    "href": "Competition/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 4"
    ]
  },
  {
    "objectID": "Competition/project3.html",
    "href": "Competition/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 3"
    ]
  },
  {
    "objectID": "Competition/project2.html",
    "href": "Competition/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 2"
    ]
  },
  {
    "objectID": "Competition/project1.html",
    "href": "Competition/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 1"
    ]
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "Machine_Learning/project3.html",
    "href": "Machine_Learning/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 3"
    ]
  },
  {
    "objectID": "Machine_Learning/project4.html",
    "href": "Machine_Learning/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 4"
    ]
  },
  {
    "objectID": "Machine_Learning/project5.html",
    "href": "Machine_Learning/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 5"
    ]
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Isaac Newtons‚Äôs CV",
    "section": "",
    "text": "Physicist, Mathematician, Cambridge professor.\n\nisaac@applesdofall.org | My wikipedia page\n\n\n\nStanding on the shoulders of giants\n\n\nLaws of motion, gravitation, minting coins, disliking Robert Hooke\n\n\n\nCooling, power series, optics, alchemy, planetary motions, apples.\n\n\n\n\n1654-1660 The King‚Äôs School, Grantham.\nJune 1661 - now Trinity College, Cambridge\n\nSizar\n\n1667 - death Trinity College, Cambridge\n\nFellow\n\n\n\n\n2012 President, Royal Society, London, UK\nAssociate, French Academy of Science, Paris, France\n\n\n\n\n\n\n1669 Newton Sir I, De analysi per √¶quationes numero terminorum infinitas.\n1669 Lectiones optic√¶.\netc. etc. etc.\n\n\n\n2012 Infinitesimal calculus for solutions to physics problems, SMBC patent 001\n\n\n\n\n1600 Royal Mint, London\n\nWarden\nMinted coins\n\n1600 Lucasian professor of Mathematics, Cambridge University"
  },
  {
    "objectID": "resume.html#currently",
    "href": "resume.html#currently",
    "title": "Isaac Newtons‚Äôs CV",
    "section": "",
    "text": "Standing on the shoulders of giants\n\n\nLaws of motion, gravitation, minting coins, disliking Robert Hooke\n\n\n\nCooling, power series, optics, alchemy, planetary motions, apples."
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Isaac Newtons‚Äôs CV",
    "section": "",
    "text": "1654-1660 The King‚Äôs School, Grantham.\nJune 1661 - now Trinity College, Cambridge\n\nSizar\n\n1667 - death Trinity College, Cambridge\n\nFellow"
  },
  {
    "objectID": "resume.html#awards",
    "href": "resume.html#awards",
    "title": "Isaac Newtons‚Äôs CV",
    "section": "",
    "text": "2012 President, Royal Society, London, UK\nAssociate, French Academy of Science, Paris, France"
  },
  {
    "objectID": "resume.html#publications",
    "href": "resume.html#publications",
    "title": "Isaac Newtons‚Äôs CV",
    "section": "",
    "text": "1669 Newton Sir I, De analysi per √¶quationes numero terminorum infinitas.\n1669 Lectiones optic√¶.\netc. etc. etc.\n\n\n\n2012 Infinitesimal calculus for solutions to physics problems, SMBC patent 001"
  },
  {
    "objectID": "resume.html#occupation",
    "href": "resume.html#occupation",
    "title": "Isaac Newtons‚Äôs CV",
    "section": "",
    "text": "1600 Royal Mint, London\n\nWarden\nMinted coins\n\n1600 Lucasian professor of Mathematics, Cambridge University"
  },
  {
    "objectID": "Story_Telling/project2.html",
    "href": "Story_Telling/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 2"
    ]
  },
  {
    "objectID": "Story_Telling/project1.html",
    "href": "Story_Telling/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 1"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project3.html",
    "href": "Cleansing_Projects/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 3"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project4.html",
    "href": "Cleansing_Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 4"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project5.html",
    "href": "Cleansing_Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 5"
    ]
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project2.html",
    "href": "Cleansing_Exploration/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project1.html",
    "href": "Cleansing_Exploration/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/Exploration_01.html#mpaa-movie-ratings",
    "href": "notebooks/Exploration_01.html#mpaa-movie-ratings",
    "title": "Data Exploration 01",
    "section": "MPAA Movie Ratings:",
    "text": "MPAA Movie Ratings:\n\nG: All ages admitted.\nPG: Some material may not be suitable for children.\nPG-13: Some material may be inappropriate for children under 13.\nR: Under 17 requires accompanying parent or adult guardian\nNC-17: No One 17 and Under Admitted\n\nMost people would consider G and PG as ratings suitable for children. However, not everyone would agree that a PG-13 movie is necssarily a children‚Äôs movie. It is up to you to decide how to handle this."
  },
  {
    "objectID": "notebooks/Exploration_01.html#part-1-import-pandas",
    "href": "notebooks/Exploration_01.html#part-1-import-pandas",
    "title": "Data Exploration 01",
    "section": "Part 1: Import Pandas",
    "text": "Part 1: Import Pandas\nThe pandas library is a python library used for data analysis and manipulation. It will provide the core functionality for most of what you do in the data exploration and preprocessing stages of most machine learning projects.\nPlease see this Getting Started Guide for information on the conventional way to import Pandas into your project, as well as other helpful tips for common Pandas tasks.\n\n# Part 1: Enter the code below to import Pandas according to the\n# conventional method."
  },
  {
    "objectID": "notebooks/Exploration_01.html#part-2-load-the-data",
    "href": "notebooks/Exploration_01.html#part-2-load-the-data",
    "title": "Data Exploration 01",
    "section": "Part 2: Load the data",
    "text": "Part 2: Load the data\nThe dataset for this exploration is stored at the following url:\nhttps://raw.githubusercontent.com/byui-cse/cse450-course/master/data/netflix_titles.csv\nThere are lots of ways to load data into your workspace. The easiest way in this case is to ask Pandas to do it for you.\n\nInitial Data Analysis\nOnce you‚Äôve loaded the data, it‚Äôs a good idea to poke around a little bit to find out what you‚Äôre dealing with.\nSome questions you might ask include:\n\nWhat does the data look like?\nWhat kind of data is in each column?\nDo any of the columns have missing values?\n\n\n# Part 2: Load the dataset into a Pandas dataframe.\n\n\n# Then, explore the data by seeing what the first few rows look like.\n\n\n# Next, display a technical summary of the data to determine the data types of each column, and which columns have missing data."
  },
  {
    "objectID": "notebooks/Exploration_01.html#part-3-filter-the-data",
    "href": "notebooks/Exploration_01.html#part-3-filter-the-data",
    "title": "Data Exploration 01",
    "section": "Part 3: Filter the Data",
    "text": "Part 3: Filter the Data\nSince we‚Äôre just interested in movies, we‚Äôll need to filter out anything that isn‚Äôt a movie for our analysis. The type feature contains this information.\nOnce we have the subset, we should see how many rows it contains. There are a variety of ways to get the length of a data frame.\n\n# Use pandas's filtering abilitites to select the subset of data\n# that represents movies, then calculate how many rows are in the filtered data.\n\n\nMPAA Ratings\nNow that we have only movies, let‚Äôs get a quick count of the values being used in the rating feature.\n\n# Determine the number of records for each value of the \"rating\" feature.\n# Remember to count the values in your subset only, not in the original dataframe.\n\n\n\nMore Filtering\nThere are apparently some ‚Äúmade for TV‚Äù movies in the list that don‚Äôt fit the MPAA rating scheme.\nLet‚Äôs filter some more to just see movies rated with the standard MPAA ratings of G, PG, PG-13, R, and NC-17.\n\n# Filter the list of movies to select a new subset containing only movies with\n# a standard MPAA rating. Calculate how many rows are in this new set, and\n# then see which ratings appear most often."
  },
  {
    "objectID": "notebooks/Exploration_01.html#part-4-visualization",
    "href": "notebooks/Exploration_01.html#part-4-visualization",
    "title": "Data Exploration 01",
    "section": "Part 4: Visualization",
    "text": "Part 4: Visualization\nNow that we have explored and preprocessed our data, let‚Äôs create a visualization to summarize our findings.\n\nExploration vs Presentation\nBroadly speaking, there are two types of visualizations: * Barebones visualizations you might use to get a quick, visual understanding of the data while you‚Äôre trying to decide how it all fits together. * Presentation-quality visualizations that you would include in a report or presentation for management or other stakeholders.\n\n\nVisualization Tools\nThere are many different visualization tools availble. In the sections below, we‚Äôll explore the three most common. Each of these libraries has strengths and weaknesses.\nIt is probably a good idea for you to become familiar with each one, and then become proficient at whichever one you like the best.\n\n\nAltair\nThe Altair visualization library provides a large variety of very easy to use statistical charting tools.\nAltair uses a declarative language to build up charts piece by piece.\nAssume we have a pandas dataframe called employees, with three columns: name, job, salary.\n# Make a box plot style categorical plot showing the distribution of salaries for each job:\nalt.Chart(employees).mark_boxplot().encode(\n    x='job',\n    y='salary'\n)\n\n# Make a box plot style categorical plot, and customize the results\nalt.Chart(employees).mark_boxplot().encode(\n    alt.X('job', title='Job title'),\n    alt.Y('salary', title='Annual salary in thousands of $USD')\n).properties(\n  title='Salaries by Job Title'\n)\nLike with Pandas, there is a conventional way to import Altair into your projects.\n\n# Import the Altair library the conventional way.\n\nLet‚Äôs create a barchart showing the count of each movie rating by using Altair‚Äôs aggregation capabilities.\nIn this example, we see the x axis being set to a feature called a, and the y axis set to the average() of a feature called b.\nIn our case, we want the x axis to be set to rating and the y axis to be the count() of rating.\n\n# Use Altair to create a bar chart comparing the count of each movie rating\n\n\n\nSeaborn\nWhile Altair uses a ‚Äúdeclarative‚Äù syntax for building charts piece by piece, the Seaborn library provides a large variety of pre-made charts for common statistical needs.\nThese charts are divided into different categories. Each category has a high-level interface you can use for simplicity, and then a specific function for each chart that you can use if you need more control over how the chart looks.\nSeaborn uses matplotlib for its drawing, and the chart-specific functions each return a matplitlib axes object if you need additional customization.\nFor example, there are several different types of categorical plots in seaborn: bar plots, box plots, point plots, count plots, swarm plots, etc‚Ä¶\nEach of these plots can be accessed using the catplot function.\nAssume we have a pandas dataframe called employees, with three columns: name, job, salary.\n# Make a box plot style categorical plot showing the distribution of salaries for each job:\nsns.catplot(data=employees, x='job', y='salary', kind='box')\n\n# Make a swarm plot style categorical plot\nsns.catplot(data=employees, x='job', y='salary', kind='swarm')\nAlternatively, you can use the plot specific functions to give yourself more control over the output by using matplotlib functions:\n# Make a box plot style categorical plot, and customize the results\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 9))\nax = sns.boxplot(data=employees, x='job', y='salary')\nax.set_title(\"Salaries by Job Title\")\nax.set_ylabel(\"Annual salary in thousands of $USD\")\nax.set_xlabel(\"Job title\")\nLike with Pandas, there is a conventional way to import Seaborn into your projects.\nOptionally, you may wish to set some default chart aesthetics by setting the chart style.\n\n# Import the seaborn library the conventional way. Then optionally configure\n# the default chart style.\n\nSince the rating column uses categorical data, we need to use Seaborn‚Äôs categorical visualizations.\nIn particular, we want a ‚Äúcount plot‚Äù that will display a count of movie ratings.\n\n# Use seaborn to create a count plot comparing the count of each movie rating\n\n\n\nPandas built-in plotting\nIn addition to libraries like Altair and Seaborn, Pandas has some built in charting functionality.\nWhile not as sophisticated as some of the other options, it is often good enough for quick visualizations.\nJust like with seaborn‚Äôs plotting functions, the pandas plotting functions return matplotlib axes objects, which can be further customized.\nAssume we have a pandas dataframe called employees, with three columns: name, job, salary.\n# Make a box plot style categorical plot showing the distribution of salaries for each job:\nemployees[ ['job','salary'] ].plot.box()\n\n# Make a box plot style categorical plot, and customize the results\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 9))\nax = employees[ ['job','salary'] ].plot().box()\nax.set_title(\"Salaries by Job Title\")\nax.set_ylabel(\"Annual salary in thousands of $USD\")\nax.set_xlabel(\"Job title\")\n\n# Use pandas' built in plotting functions to create a count plot comparing the count of each movie rating\n# This will be a little trickier than the other libraries, but one hint is that the pandas value_counts() function\n# actually returns a dataframe."
  },
  {
    "objectID": "notebooks/Exploration_01.html#above-and-beyond",
    "href": "notebooks/Exploration_01.html#above-and-beyond",
    "title": "Data Exploration 01",
    "section": "üåü Above and Beyond üåü",
    "text": "üåü Above and Beyond üåü\nAfter reviewing your findings, the watchdog group would like some additional questions answered:\n\nHow are things affected if you include the ‚Äúmade for TV movies‚Äù that have been assigned TV ratings in your analysis, but still exclude unrated movies?\nThey would also like to see a separate report that includes only TV shows.\nFor an upcoming community meeting, the group would like to present a simple chart showing ‚ÄúFor Kids‚Äù and ‚ÄúFor Adults‚Äù categories. The easiest way to accomplish this would be to create a new column in your data frame that maps each rating to the appropriate ‚ÄúFor Kids‚Äù or ‚ÄúFor Adults‚Äù label, then create a new visualization based on that column."
  },
  {
    "objectID": "notebooks/starter_bank.html",
    "href": "notebooks/starter_bank.html",
    "title": "Jaeli Jaussi - Data Science Portfolio",
    "section": "",
    "text": "The core task we‚Äôre interested in is identifying those customers most likely to subscribe to a term deposit.\nA term deposit is a fixed-term investment that includes the deposit of money into an account at a financial institution. In this case, our financial institution.\nI don‚Äôt know a lot about data science, but I‚Äôve been trying to get up to speed. Do you think a supervised or unsupervised approach would work best for this situation?\nSupervised with a tree model. We want to predict the y column (whether someone will make a term deposit) based on the other categorical data.\nMiguel, that is a great question.\nWhile we are asking detailed questions, the dataset has approximately 37,000 records. How much of that data will you use to train your model?\nBased on your initial analysis of the data, your team feels:\nA simple 80/20 split will provide us with enough to accurately train and test our model. A 50/50 split so that we have the same amount of training data as testing. We will pull out 1,000 records for our test dataset and use the other 36,000 for training. This gives our model more to train on and will produce better results. We will use all 37,000 for training and use cross-validation to evaluate the model.\n80/20 split for training and testing\nAside from the core marketing question Miguel mentioned, I‚Äôm wondering if there are other insights we could gain from our data.\nI can look at the data and tell that some days of the week or some months produce better results than others.\nI‚Äôm wondering if it‚Äôs possible for us to see if those results are true for all customers, or if some types of customers respond better on certain days than others?\nSince we‚Äôre operating in the European Union, we‚Äôre subject to GDPR compliance requirements.\nWhat do you think we might need to do for this project in order to be compliant with GDPR regulations?\nBeatriz, Senior Data Scientist asks: Since we‚Äôre operating in the European Union, we‚Äôre subject to GDPR compliance requirements.\nWhat do you think we might need to do for this project in order to be compliant with GDPR regulations?\nBased on your initial analysis of the data, your team feels:\nThis is historic data, so we should be just fine. This is anonymous data, so we should be just fine. The GDPR doesn‚Äôt apply in this situation, since we‚Äôre just building a model, not selling data. In order to use this data under GDPR, we‚Äôll need to get consent from the customers in the dataset.\nGDPR does not apply because our data is anonymous.\nWho is more likely to make a term deposit?\nOther questions to answer\n\nWhich people should be called on which day/month? Robert and Shaun\nDoes frequent contact poorly affect marketing campaigns? Dylan\nMake different models for different economic contexts. Jaeli and Peter\n\n\nimport pandas as pd\n\ncampaign = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bank.csv')\n\ncampaign.head()\ncampaign.info()\ncampaign.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 37069 entries, 0 to 37068\nData columns (total 20 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   age             37069 non-null  int64  \n 1   job             37069 non-null  object \n 2   marital         37069 non-null  object \n 3   education       37069 non-null  object \n 4   default         37069 non-null  object \n 5   housing         37069 non-null  object \n 6   loan            37069 non-null  object \n 7   contact         37069 non-null  object \n 8   month           37069 non-null  object \n 9   day_of_week     37069 non-null  object \n 10  campaign        37069 non-null  int64  \n 11  pdays           37069 non-null  int64  \n 12  previous        37069 non-null  int64  \n 13  poutcome        37069 non-null  object \n 14  emp.var.rate    37069 non-null  float64\n 15  cons.price.idx  37069 non-null  float64\n 16  cons.conf.idx   37069 non-null  float64\n 17  euribor3m       37069 non-null  float64\n 18  nr.employed     37069 non-null  float64\n 19  y               37069 non-null  object \ndtypes: float64(5), int64(4), object(11)\nmemory usage: 5.7+ MB\n\n\n\n    \n\n\n\n\n\n\nage\ncampaign\npdays\nprevious\nemp.var.rate\ncons.price.idx\ncons.conf.idx\neuribor3m\nnr.employed\n\n\n\n\ncount\n37069.000000\n37069.000000\n37069.000000\n37069.000000\n37069.000000\n37069.000000\n37069.000000\n37069.000000\n37069.000000\n\n\nmean\n40.025493\n2.564407\n962.221803\n0.173730\n0.081526\n93.576551\n-40.494829\n3.621945\n5167.010650\n\n\nstd\n10.435288\n2.764084\n187.531477\n0.496159\n1.572287\n0.579339\n4.628895\n1.734496\n72.294476\n\n\nmin\n17.000000\n1.000000\n0.000000\n0.000000\n-3.400000\n92.201000\n-50.800000\n0.634000\n4963.600000\n\n\n25%\n32.000000\n1.000000\n999.000000\n0.000000\n-1.800000\n93.075000\n-42.700000\n1.344000\n5099.100000\n\n\n50%\n38.000000\n2.000000\n999.000000\n0.000000\n1.100000\n93.749000\n-41.800000\n4.857000\n5191.000000\n\n\n75%\n47.000000\n3.000000\n999.000000\n0.000000\n1.400000\n93.994000\n-36.400000\n4.961000\n5228.100000\n\n\nmax\n98.000000\n56.000000\n999.000000\n7.000000\n1.400000\n94.767000\n-26.900000\n5.045000\n5228.100000\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n  \n\n\n\nimport seaborn as sns\n\ndf_day= (\n    campaign\n      .groupby('day_of_week')\n      .agg(\n          total=('y', 'size'),\n          y_yes=('y', lambda x: (x== \"yes\").sum())\n      )\n      .reset_index()\n)\nsns.barplot(\n    data=df_day,\n    x='day_of_week',\n    y='y_yes'\n)\n\n\n\n\n\n\n\n\n\ndf_day= (\n    campaign[campaign['job']== 'student']\n      .groupby('day_of_week')\n      .agg(\n          total=('y', 'size'),\n          y_yes=('y', lambda x: (x== \"yes\").sum())\n      )\n      .reset_index()\n)\nsns.barplot(\n    data=df_day,\n    x='day_of_week',\n    y='y_yes'\n)\n\n\n\n\n\n\n\n\nMake different models for different economic contexts.\n\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report\n\ndf = campaign.copy()\n\n# Convert target variable\ndf['y'] = df['y'].map({'yes': 1, 'no': 0})\n\n# Encode categorical variables\nX = pd.get_dummies(df.drop(columns='y'), drop_first=True)\ny = df['y']\n\ndf['econ_context'] = pd.qcut(\n    df['euribor3m'],\n    q=5,\n    labels=False\n)\n\nmodels = {}\n\nfor context in range(5):\n    print(f\"\\nEconomic Context {context}\")\n    print(\"-\" * 40)\n\n    # Filter data for context\n    context_idx = df['econ_context'] == context\n    X_context = X.loc[context_idx]\n    y_context = y.loc[context_idx]\n\n    # Train / test split\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_context,\n        y_context,\n        test_size=0.2,\n        random_state=42,\n        stratify=y_context\n    )\n\n    # Decision Tree model\n    model = DecisionTreeClassifier(\n        max_depth=6,\n        min_samples_leaf=50,\n        random_state=42\n    )\n\n    model.fit(X_train, y_train)\n\n    # Evaluate\n    y_pred = model.predict(X_test)\n    print(classification_report(y_test, y_pred))\n\n    # Store model\n    models[context] = model\n\n\nEconomic Context 0\n----------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.77      0.93      0.84      1089\n           1       0.69      0.36      0.47       465\n\n    accuracy                           0.76      1554\n   macro avg       0.73      0.65      0.66      1554\nweighted avg       0.75      0.76      0.73      1554\n\n\nEconomic Context 1\n----------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.90      0.99      0.94      1349\n           1       0.43      0.09      0.15       166\n\n    accuracy                           0.89      1515\n   macro avg       0.66      0.54      0.54      1515\nweighted avg       0.85      0.89      0.85      1515\n\n\nEconomic Context 2\n----------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98      1472\n           1       0.00      0.00      0.00        54\n\n    accuracy                           0.96      1526\n   macro avg       0.48      0.50      0.49      1526\nweighted avg       0.93      0.96      0.95      1526\n\n\nEconomic Context 3\n----------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.94      1.00      0.97      1450\n           1       0.00      0.00      0.00        85\n\n    accuracy                           0.94      1535\n   macro avg       0.47      0.50      0.49      1535\nweighted avg       0.89      0.94      0.92      1535\n\n\nEconomic Context 4\n----------------------------------------\n              precision    recall  f1-score   support\n\n           0       0.94      1.00      0.97      1213\n           1       0.00      0.00      0.00        72\n\n    accuracy                           0.94      1285\n   macro avg       0.47      0.50      0.49      1285\nweighted avg       0.89      0.94      0.92      1285\n\n\n\n/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ncampaign = pd.read_csv(\n    'https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bank.csv'\n)\n\nModel 1: Employment Variation Rate (emp.var.rate)\nQuestion: How does subscription success vary by employment conditions?\n\ncampaign['emp_bin'] = pd.qcut(\n    campaign['emp.var.rate'],\n    q=4,\n    duplicates='drop'\n)\n\ndf_emp = (\n    campaign\n      .groupby('emp_bin')\n      .agg(\n          total=('y', 'size'),\n          y_yes=('y', lambda x: (x == 'yes').sum())\n      )\n      .reset_index()\n)\n\nsns.barplot(\n    data=df_emp,\n    x='emp_bin',\n    y='y_yes'\n)\nplt.xticks(rotation=45)\nplt.title('Subscriptions by Employment Variation Rate')\nplt.show()\n\n/tmp/ipython-input-3855154566.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  .groupby('emp_bin')\n\n\n\n\n\n\n\n\n\nModel 2: Consumer Price Index (cons.price.idx)\nQuestion: Do higher prices affect campaign success?\n\ncampaign['price_bin'] = pd.qcut(\n    campaign['cons.price.idx'],\n    q=4,\n    duplicates='drop'\n)\n\ndf_price = (\n    campaign\n      .groupby('price_bin')\n      .agg(\n          total=('y', 'size'),\n          y_yes=('y', lambda x: (x == 'yes').sum())\n      )\n      .reset_index()\n)\n\nsns.barplot(\n    data=df_price,\n    x='price_bin',\n    y='y_yes'\n)\nplt.xticks(rotation=45)\nplt.title('Subscriptions by Consumer Price Index')\nplt.show()\n\n/tmp/ipython-input-3001552865.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  .groupby('price_bin')\n\n\n\n\n\n\n\n\n\nModel 3: Consumer Confidence Index (cons.conf.idx)\nQuestion: Does consumer confidence correlate with success?\n\ncampaign['conf_bin'] = pd.qcut(\n    campaign['cons.conf.idx'],\n    q=4,\n    duplicates='drop'\n)\n\ndf_conf = (\n    campaign\n      .groupby('conf_bin')\n      .agg(\n          total=('y', 'size'),\n          y_yes=('y', lambda x: (x == 'yes').sum())\n      )\n      .reset_index()\n)\n\nsns.barplot(\n    data=df_conf,\n    x='conf_bin',\n    y='y_yes'\n)\nplt.xticks(rotation=45)\nplt.title('Subscriptions by Consumer Confidence Index')\nplt.show()\n\n/tmp/ipython-input-2892907372.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  .groupby('conf_bin')\n\n\n\n\n\n\n\n\n\nModel 4: Euribor 3-Month Rate (euribor3m)\nQuestion: How do interest rates impact subscriptions?\n\ncampaign['euribor_bin'] = pd.qcut(\n    campaign['euribor3m'],\n    q=4,\n    duplicates='drop'\n)\n\ndf_euribor = (\n    campaign\n      .groupby('euribor_bin')\n      .agg(\n          total=('y', 'size'),\n          y_yes=('y', lambda x: (x == 'yes').sum())\n      )\n      .reset_index()\n)\n\nsns.barplot(\n    data=df_euribor,\n    x='euribor_bin',\n    y='y_yes'\n)\nplt.xticks(rotation=45)\nplt.title('Subscriptions by Euribor 3M Rate')\nplt.show()\n\n/tmp/ipython-input-4186568377.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  .groupby('euribor_bin')\n\n\n\n\n\n\n\n\n\nModel 5: Number of Employed (nr.employed)\nQuestion: Does overall employment level matter?\n\ncampaign['employed_bin'] = pd.qcut(\n    campaign['nr.employed'],\n    q=4,\n    duplicates='drop'\n)\n\ndf_employed = (\n    campaign\n      .groupby('employed_bin')\n      .agg(\n          total=('y', 'size'),\n          y_yes=('y', lambda x: (x == 'yes').sum())\n      )\n      .reset_index()\n)\n\nsns.barplot(\n    data=df_employed,\n    x='employed_bin',\n    y='y_yes'\n)\nplt.xticks(rotation=45)\nplt.title('Subscriptions by Number Employed')\nplt.show()\n\n/tmp/ipython-input-3004665151.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  .groupby('employed_bin')\n\n\n\n\n\n\n\n\n\nEmployment Variation Rate ‚Üí Line Plot (Trend)\nWhy: emp.var.rate is time-based and ordered. A line plot highlights trends.\n\ndf_emp = (\n    campaign\n      .groupby('emp.var.rate')\n      .agg(\n          subscribe_rate=('y', lambda x: (x == 'yes').mean())\n      )\n      .reset_index()\n      .sort_values('emp.var.rate')\n)\n\nsns.lineplot(\n    data=df_emp,\n    x='emp.var.rate',\n    y='subscribe_rate',\n    marker='o'\n)\nplt.title('Subscription Rate vs Employment Variation Rate')\nplt.ylabel('Subscription Rate')\nplt.show()\n\n\n\n\n\n\n\n\nConsumer Price Index ‚Üí Box Plot\nWhy: CPI varies continuously, and boxplots show spread + outliers well.\n\nsns.boxplot(\n    data=campaign,\n    x='y',\n    y='cons.price.idx'\n)\nplt.title('Consumer Price Index by Subscription Outcome')\nplt.xlabel('Subscribed')\nplt.ylabel('Consumer Price Index')\nplt.show()\n\n\n\n\n\n\n\n\nA violin plot shows how your data is distributed and key summary statistics at the same time.\nThink of it as:\nHistogram + boxplot = violin plot\n\nWidth = how common values are\n\nThis is the most important thing.\nWide sections ‚Üí lots of observations there\nNarrow sections ‚Üí fewer observations\nSo if the violin is fat around ‚àí40 and skinny around ‚àí30, most data points are near ‚àí40.\nRule of thumb:\nWider = more common\n\nHeight = actual data values\n\nThe top to bottom of the violin shows:\nMinimum to maximum values of the variable\nThe y-axis numbers are real data values\nExample for cons.conf.idx:\nBottom: very low confidence\nTop: higher confidence\n\nThe inside lines (quartiles & median)\n\nBecause you used:\ninner=‚Äòquartile‚Äô\nYou‚Äôll see three horizontal lines inside each violin:\nLine Meaning Middle line Median (50th percentile) Lower line 25th percentile Upper line 75th percentile\nThis tells you:\nWhere the typical value is\nHow spread out the middle 50% is\nConsumer Confidence Index ‚Üí Violin Plot\nWhy: Confidence is sentiment-based; violins show distribution shape better than boxes.\n\nsns.violinplot(\n    data=campaign,\n    x='y',\n    y='cons.conf.idx',\n    inner='quartile'\n)\nplt.title('Consumer Confidence by Subscription Outcome')\nplt.xlabel('Subscribed')\nplt.ylabel('Consumer Confidence Index')\nplt.show()\n\n\n\n\n\n\n\n\nEuribor 3-Month Rate ‚Üí Histogram with Hue\nWhy: Interest rates affect behavior gradually; overlapping distributions work well.\n\nsns.histplot(\n    data=campaign,\n    x='euribor3m',\n    hue='y',\n    bins=30,\n    kde=True,\n    element='step'\n)\nplt.title('Euribor 3M Rate Distribution by Subscription Outcome')\nplt.xlabel('Euribor 3M Rate')\nplt.show()\n\n\n\n\n\n\n\n\nNumber Employed ‚Üí Scatter + Regression Line\nWhy: nr.employed is large-scale and continuous; scatter + trend shows correlation.\n\ndf_emp_level = (\n    campaign\n      .groupby('nr.employed')\n      .agg(\n          subscribe_rate=('y', lambda x: (x == 'yes').mean())\n      )\n      .reset_index()\n)\n\nsns.regplot(\n    data=df_emp_level,\n    x='nr.employed',\n    y='subscribe_rate',\n    scatter_kws={'alpha': 0.6},\n    line_kws={'color': 'black'}\n)\nplt.title('Subscription Rate vs Number Employed')\nplt.ylabel('Subscription Rate')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Full_Stack/project2.html",
    "href": "Full_Stack/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 2"
    ]
  },
  {
    "objectID": "Full_Stack/project1.html",
    "href": "Full_Stack/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 1"
    ]
  }
]